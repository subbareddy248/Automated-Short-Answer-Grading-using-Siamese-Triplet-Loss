{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = '/home/adithya/glove.6B/glovew2v.6B.100d.txt'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('recomendados', 0.6044833064079285)]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['evaporate'], negative=['water','sun'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14574410646849545\n",
      "[('quaff', 0.5747246146202087), ('flaunt', 0.5675700902938843), ('internalize', 0.5549746751785278), ('excretes', 0.5462298393249512), ('assimilate', 0.5260298252105713), ('overeat', 0.5237395763397217), ('metabolize', 0.5203923583030701), ('sublimate', 0.5196496844291687), ('overanalyze', 0.5181325674057007), ('partake', 0.5151299238204956)]\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('evaporate','sun'))\n",
    "print(model.most_similar('imbibe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def morphify(word):\n",
    "\n",
    "    \"\"\" morph a word \"\"\"\n",
    "    #synsets = wn.synsets(word, pos=org_pos)\n",
    "    synsets = wn.synsets(word)\n",
    "\n",
    "    # Word not found\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Get all  lemmas of the word\n",
    "    #lemmas = [l for s in synsets for l in s.lemmas() if s.name().split('.')[1] == org_pos]\n",
    "    lemmas = [l for s in synsets for l in s.lemmas()]\n",
    "\n",
    "    # Get related forms\n",
    "    derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "\n",
    "    # filter only the targeted pos\n",
    "    #related_lemmas = [l for drf in derivationally_related_forms for l in drf[1] if l.synset().name().split('.')[1] == target_pos]\n",
    "    related_lemmas = [l for drf in derivationally_related_forms for l in drf[1]]\n",
    "    related_lemmas2 = [drf[0] for drf in derivationally_related_forms]\n",
    "\n",
    "    # Extract the words from the lemmas\n",
    "    #words = [l.name() for l in related_lemmas]\n",
    "    words = []\n",
    "    for l in related_lemmas:\n",
    "        words.append(l.synset().name().split('.')[0])\n",
    "        words.append(l.name())\n",
    "    for l in related_lemmas2:\n",
    "        words.append(l.synset().name().split('.')[0])\n",
    "        words.append(l.name())\n",
    "\n",
    "    return set(words)\n",
    "\n",
    "#print(morphify('runs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mellow', 'heights', 'high_school', 'luxuriously', 'high-pitched', 'eminent', 'high_gear', 'gamey', 'eminence', 'in_high_spirits', 'gamy', 'senior_high', 'senior_high_school', 'highness', 'game', 'mellowness', 'richly', 'highschool', 'high', 'high_up'}\n",
      "mellow  NOT PRESENT IN VOCAB\n",
      "heights  NOT PRESENT IN VOCAB\n",
      "high  NOT PRESENT IN VOCAB\n",
      "luxuriously  NOT PRESENT IN VOCAB\n",
      "high-pitched  NOT PRESENT IN VOCAB\n",
      "eminent  NOT PRESENT IN VOCAB\n",
      "high  NOT PRESENT IN VOCAB\n",
      "gamey  NOT PRESENT IN VOCAB\n",
      "eminence  NOT PRESENT IN VOCAB\n",
      "in  NOT PRESENT IN VOCAB\n",
      "gamy  NOT PRESENT IN VOCAB\n",
      "senior  NOT PRESENT IN VOCAB\n",
      "senior  NOT PRESENT IN VOCAB\n",
      "highness  NOT PRESENT IN VOCAB\n",
      "game  NOT PRESENT IN VOCAB\n",
      "mellowness  NOT PRESENT IN VOCAB\n",
      "richly  NOT PRESENT IN VOCAB\n",
      "highschool  NOT PRESENT IN VOCAB\n",
      "high  NOT PRESENT IN VOCAB\n",
      "high  NOT PRESENT IN VOCAB\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#a = ['string','pitch','short']\n",
    "b = morphify('high')\n",
    "print(b)\n",
    "dictio = {}\n",
    "for c in b:\n",
    "    if '_' in c:\n",
    "        c = c.split('_')[0]\n",
    "    try :\n",
    "        z = 0\n",
    "        for d in a:\n",
    "            x = model.similarity(d,c)\n",
    "            z += x\n",
    "        #dictio[c] = z\n",
    "        dictio[c] = (z / len(a))\n",
    "    except:\n",
    "        print(c,' NOT PRESENT IN VOCAB')\n",
    "\n",
    "z = sorted(dictio.items(), key=lambda x: x[1], reverse=True)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = ['high','string','pitch','short']\n",
    "def query_expansion(keyword_list):\n",
    "    finalwordslist = []\n",
    "    for word in keyword_list:\n",
    "        #print(word)\n",
    "        a = keyword_list.copy()\n",
    "        a.remove(word)\n",
    "        #print(a)\n",
    "        b = morphify(word)\n",
    "        #print(b)\n",
    "        dictio = {}\n",
    "        for c in b:\n",
    "            if '_' in c:\n",
    "                c = c.split('_')[0]\n",
    "            try :\n",
    "                z = 0\n",
    "                for d in a:\n",
    "                    x = model.similarity(d,c)\n",
    "                    z += x\n",
    "                #dictio[c] = z\n",
    "                dictio[c] = (z / len(a))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        z = sorted(dictio.items(), key=lambda x: x[1], reverse=True)\n",
    "        #print(z[0:5])\n",
    "        #print('\\n')\n",
    "        for eachword in z[0:5]:\n",
    "            finalwordslist.append(eachword[0])\n",
    "    wordslist = [stemmer.stem(plural) for plural in finalwordslist]\n",
    "    return wordslist\n",
    "keywords = ['Water', 'evaporates', 'sun', 'leaving', 'salt'] \n",
    "#query_expansion(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#text = \"Water evaporates in the sun, leaving behind salt\"\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_similarword(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    keywords_dict = {}\n",
    "    keywords = []\n",
    "    for token in doc:\n",
    "        if 'NN' in token.tag_ or 'VB' in token.tag_:\n",
    "            keywords_dict[token.text] = token.tag_\n",
    "            keywords.append(token.text.lower())\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    \n",
    "    #print(keywords)\n",
    "    similarwords = query_expansion(keywords)\n",
    "    return similarwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4969\n",
      "4969\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "ans_pairs = pickle.load(open(\"./pairs\",\"rb\"))    #reference answer and student answer\n",
    "labels = pickle.load(open(\"./labels\",\"rb\"))      #correct or incorrect are the labels\n",
    "print(len(labels))   # number of labels\n",
    "print(len(ans_pairs)) #number of question pairs\n",
    "print(len(list(set(labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_list = []\n",
    "student_list = []\n",
    "for i in range(len(labels)):\n",
    "    reference_list.append(generate_similarword(ans_pairs[i][0]))\n",
    "    student_list.append(generate_similarword(ans_pairs[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['take', 'draw', 'absorb', 'concentr', 'soak', 'heat', 'hot', 'high', 'fire', 'heat', 'full', 'energi', 'free', 'push', 'depart', 'clean', 'white', 'snow', 'egg', 'blank', 'think', 'reflect', 'shine', 'reflect', 'specul', 'heat', 'hot', 'high', 'fire', 'heat', 'full', 'energi', 'free', 'push', 'depart', 'cover', 'cover', 'cut', 'top', 'get', 'box', 'packag', 'packag', 'corner', 'pack', 'heat', 'hot', 'high', 'fire', 'heat', 'cover', 'cover', 'cut', 'top', 'get', 'box', 'packag', 'packag', 'corner', 'pack']\n"
     ]
    }
   ],
   "source": [
    "print(reference_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabels = []\n",
    "for i in range(len(labels)):\n",
    "    if(len(set(reference_list[i]) & set(student_list[i])) > 5):\n",
    "        testlabels.append(1)\n",
    "    else:\n",
    "        testlabels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.56      0.61      2961\n",
      "          1       0.48      0.59      0.53      2008\n",
      "\n",
      "avg / total       0.59      0.57      0.58      4969\n",
      "\n",
      "[[1650 1311]\n",
      " [ 816 1192]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(labels,testlabels))\n",
    "print(confusion_matrix(labels,testlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
